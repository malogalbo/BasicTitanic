{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 22,
main
      "source": [
        "import sys\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import KBinsDiscretizer\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "from sklearn import tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
 main
      "source": [
        "url = 'https://raw.githubusercontent.com/malogalbo/BasicTitanic/main/data/test.csv'\n",
        "test_data = pd.read_csv(url, encoding='cp1252', index_col = 0, on_bad_lines = \"skip\")\n",
        "url = 'https://raw.githubusercontent.com/malogalbo/BasicTitanic/main/data/train.csv'\n",
        "train_data = pd.read_csv(url, encoding='cp1252', index_col = 0, on_bad_lines = \"skip\")"
      ]
    },
    {
 main
      "cell_type": "markdown",
      "metadata": {
        "id": "n2XSwjiXrBHk"
      },
      "source": [
        "# Loading and Pre-Processing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
     main
      "source": [
        "def train_val_split(x, y, prop_vec, shuffle=True, seed=None):\n",
        "\n",
        "    assert x.shape[0] == y.shape[0]\n",
        "    prop_vec = prop_vec / np.sum(prop_vec) # normalize\n",
        "\n",
        "    n = x.shape[0]\n",
        "    n_train = int(np.ceil(n * prop_vec[0]))\n",
        "    n_val = n - n_train\n",
        "\n",
        "    assert np.amin([n_train, n_val]) >= 1   \n",
        "\n",
        "    if shuffle:\n",
        "        rng = np.random.default_rng(seed)\n",
        "        pi = rng.permutation(n)\n",
        "    else:\n",
        "        pi = np.arange(0, n)\n",
        "\n",
        "    pi_train = pi[0:n_train]\n",
        "    pi_val = pi[n_train:n]\n",
        "\n",
        "    train_x = x[pi_train]\n",
        "    train_y = y[pi_train]\n",
        "\n",
        "    val_x = x[pi_val]\n",
        "    val_y = y[pi_val]  \n",
        "    \n",
        "    return train_x, train_y, val_x, val_y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vybHflz3o7BM"
      },
      "source": [
        "One Hot Encode:\n",
        "\"Pclass\" 3rd, \"Embarked\" \n",
        "\n",
        "From String to Bool:\n",
        "\"Sex\" 5th\n",
        "\n",
        "Normalize/Standardize\n",
        "\"Fare\"\n",
        "\"Age\"\n",
        "\"Parch\"\n",
        "\"sibsp\"\n",
        "\n",
        "\n",
        "Ignore/Rid \n",
        "\"Name\" 4th\n",
        "PassengerID 1st\n",
        "\"ticket\"\n",
        "\n",
        "\n",
        "Perhaps?\n",
        "\"Cabin\"\n",
        "\n",
        "\n",
        "y-column:\n",
        "\"Survived\" 2nd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "source": [
        "#4,5,6 \n",
        "print(train_data.info())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 891 entries, 1 to 891\n",
            "Data columns (total 11 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   Survived  891 non-null    int64  \n",
            " 1   Pclass    891 non-null    int64  \n",
            " 2   Name      891 non-null    object \n",
            " 3   Sex       891 non-null    object \n",
            " 4   Age       714 non-null    float64\n",
            " 5   SibSp     891 non-null    int64  \n",
            " 6   Parch     891 non-null    int64  \n",
            " 7   Ticket    891 non-null    object \n",
            " 8   Fare      891 non-null    float64\n",
            " 9   Cabin     204 non-null    object \n",
            " 10  Embarked  889 non-null    object \n",
            "dtypes: float64(2), int64(4), object(5)\n",
            "memory usage: 83.5+ KB\n",
            "None\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def removeSpecifiedColums(df, names):\n",
        "    for name in names:\n",
        "        if name in df.columns:\n",
        "            df = df.drop(name, axis=1)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 21,
 main
      "source": [
        "# Clean According To Above\n",
        "\n",
        "# Extract y-column from training\n",
        "\n",
        "# Then Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_data = test_data.to_numpy()\n",
        "train_data = train_data.to_numpy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#one hot encode categorical variables\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "encoder = OneHotEncoder(handle_unknown='ignore')\n",
        "\n",
        "features_to_standardize = [2, 8]\n",
        "\n",
        "#train_x\n",
        "tmp = encoder.fit_transform(train_x[:, features_to_standardize]).toarray() #encode data\n",
        "\n",
        "train_x = np.delete(train_x, features_to_standardize, 1) #delete all old cat columns, 1 for col\n",
        "train_x = np.concatenate((train_x, tmp), axis = 1) #add encoded variables to train_x\n",
        "\n",
        "#test_x\n",
        "tmp = encoder.fit_transform(test_x[:, features_to_standardize]).toarray()\n",
        "\n",
        "test_x = np.delete(test_x, features_to_standardize, 1) #delete all old cat columns, 1 for col\n",
        "test_x = np.concatenate((test_x, tmp), axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#convert sex from string to bool\n",
        "for i, sex in enumerate(train_x.T[3]): \n",
        "    if (sex == \"male\"):\n",
        "        train_x[i, 3] = 1\n",
        "    else: \n",
        "        train_x[i, 3] = 0\n",
        "for i, sex in enumerate(test_x.T[3]): \n",
        "    if (sex == \"male\"):\n",
        "        test_x[i, 3] = 1\n",
        "    else: \n",
        "        test_x[i, 3] = 0\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Titanic Work.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "CIS4930",
      "language": "python",
      "name": "cis4930"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
